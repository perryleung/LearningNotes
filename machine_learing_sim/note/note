1、如果一个程序在使用既有的经验(E)执行某类任务(T)，的过程中被认定为是“具备学习能力的”，那么它一定需要展现出：利用现有的经验(E)，不断改善其完成既定任务(T)的性能(P)的特性

2、监督学习关注事物未知表现的预测，一般包括分类(Classification，离散)问题和回归(Regression，连续)问题

3、无监督学习关注事物本身特性的分析，常用的技术包括数据降维(Dimensionality Reduction)和聚类问题(Clustering)等

4、聚类不同分类，聚类依赖于数据的相似性，把相似的数据样本划分为一个簇，我们大多数情况下不会预先知道簇的数量和每个簇的具体含义

5、习惯性把数据视作经验，通常把这些反映数据内在规律的信息称为特征，在监督学习问题中我们的经验有特征、标记/目标(Label/Target);无监督学习自然没有标记/目标，因此无法从事预测活动，但是却适合数据结构的分析

6、要保证测试集中的数据样本一定不能被用于训练模型

7、numpy除了提供一些高级的数学运算机制以外，还具备非常高效的向量和矩阵运算功能；Scipy则是在numpy的基础上构建的更为强大，应用领域也更为广泛的科学计算包；matplotlib是一款Python编程环境下免费使用的绘图工具包，其工作方式和绘图命令几乎和matla一致；scikit-learn封装了大量经典以及最新的机器学习模型；pandas是一款针对于数据处理和分析的Python工具包

8、调用data_test = pd.read_csv('../xxx/xxx/xxx.csv')

9、分类学习是常见的监督学习，有最基础的二分类就是判断是非从两个类别中选出一个结果，另外派生的是多分类；还有多标签分类问题是判断一个样本是否同时属于多个不同类别

10、线性分类器：是一种假设特征与分类结果存在线性关系的模型，此模型通过累加计算每个维度的特征与各自权重的乘积来帮助类别决策

11、逻辑斯蒂函数就是sigmoid函数

12、在线性分类器的训练中，我们希望逻辑斯蒂函数可以在训练集上取得最大似然估计(Maximum Likelihood)的概率，就是如下：L(w,b)，而argmax L(w,b)

13、不管是梯度上升(SGA)还是梯度下降(SGD)都隶属于用梯度法迭代渐进估计参数的过程，梯度上升用于目标最大化，梯度下降用于目标最小化

14、













































